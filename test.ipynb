{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text label\n",
       "0  3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...   NEG\n",
       "1       cha3eb fey9elkoum menghir ta7ayoul ou kressi   NEG\n",
       "2  bereau degage nathef ya slim walahi ya7chiw fi...   NEG\n",
       "3                                          ak slouma   POS\n",
       "4  entom titmanou lina a7na 3iid moubarik a7na ch...   NEG\n",
       "5  hhhhhhhh blidaa minik ba3d doussieet athika il...   POS\n",
       "6                                    wahdek big boss   POS\n",
       "7    9arwwwwii yhbb 3alaa bouwahh la7niynn 5hndhawii   NEG\n",
       "8  ti blaad faasda ya hsouna hedheka el wa9a3 b a...   NEG\n",
       "9                             3omra ma9boula si slim   POS"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cha3eb fey9elkoum menghir ta7ayoul ou kressi</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bereau degage nathef ya slim walahi ya7chiw fi...</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ak slouma</td>\n      <td>POS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>entom titmanou lina a7na 3iid moubarik a7na ch...</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>hhhhhhhh blidaa minik ba3d doussieet athika il...</td>\n      <td>POS</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>wahdek big boss</td>\n      <td>POS</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>9arwwwwii yhbb 3alaa bouwahh la7niynn 5hndhawii</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ti blaad faasda ya hsouna hedheka el wa9a3 b a...</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3omra ma9boula si slim</td>\n      <td>POS</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv('data/Train.csv',encoding='utf8')\n",
    "data = data.drop(['ID'], axis=1)\n",
    "data.loc[data['label'] == -1,'label'] = 'NEG'\n",
    "data.loc[(data.label == 0),'label'] = 'NEU'\n",
    "data.loc[(data.label == 1),'label'] = 'POS'\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(data, test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train.txt',sep='\\t',encoding='utf8',header=None,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/valid.txt',sep='\\t',encoding='utf8',header=None,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading and preparing dataset sentiment_analysis/sentiment_analysis (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\Aymen Jemi\\.cache\\huggingface\\datasets\\sentiment_analysis\\sentiment_analysis\\1.0.0\\060e603059ed58f60d96587e6c538e1fa517845718c69714731868f4a2fc4872...\n",
      "Dataset sentiment_analysis downloaded and prepared to C:\\Users\\Aymen Jemi\\.cache\\huggingface\\datasets\\sentiment_analysis\\sentiment_analysis\\1.0.0\\060e603059ed58f60d96587e6c538e1fa517845718c69714731868f4a2fc4872. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel, load_dataset, load_metric\n",
    "datasets = load_dataset('sa_generator.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 49000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 21000\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "datasets"
   ]
  }
 ]
}